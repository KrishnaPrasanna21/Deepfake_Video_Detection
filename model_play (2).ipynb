{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb-V2pJ6WRyQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDP3DJC6-tQV",
        "outputId": "4ecf1880-3762-4906-88b3-41e5bd050761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeGqRoftWRyU"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/drive/MyDrive/deepfake-detection-model1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiU7i7pjmfTR",
        "outputId": "a74ffcc4-10ec-4cd4-9c1d-56f0caaad0fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Predicted class: 1\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted class: 1\n"
          ]
        }
      ],
      "source": [
        "input_shape = (128, 128, 3)\n",
        "pr_data = []\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/data/real/id2_0009.mp4')\n",
        "frameRate = cap.get(5)\n",
        "while cap.isOpened():\n",
        "    frameId = cap.get(1)\n",
        "    ret, frame = cap.read()\n",
        "    if ret != True:\n",
        "        break\n",
        "    if frameId % ((int(frameRate)+1)*1) == 0:\n",
        "        face_rects, scores, idx = detector.run(frame, 0)\n",
        "        for i, d in enumerate(face_rects):\n",
        "            x1 = d.left()\n",
        "            y1 = d.top()\n",
        "            x2 = d.right()\n",
        "            y2 = d.bottom()\n",
        "            crop_img = frame[y1:y2, x1:x2]\n",
        "            data = (cv2.resize(crop_img, (128, 128))) / 255.0\n",
        "            data = data.reshape( -1,128, 128, 3)\n",
        "            prediction=model.predict(data)\n",
        "            prediction_threshold = 0.5\n",
        "            if prediction >= prediction_threshold:\n",
        "                   predicted_class = 1\n",
        "            else:\n",
        "                   predicted_class = 0\n",
        "\n",
        "            print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eus9ZBcFeVYt",
        "outputId": "0d4386c0-5968-4aaf-b56f-726d8c6a6608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 532ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted class: 0\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Predicted class: 0\n"
          ]
        }
      ],
      "source": [
        "input_shape = (128, 128, 3)\n",
        "pr_data = []\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/data/fake/id0_id16_0004.mp4')\n",
        "frameRate = cap.get(5)\n",
        "while cap.isOpened():\n",
        "    frameId = cap.get(1)\n",
        "    ret, frame = cap.read()\n",
        "    if ret != True:\n",
        "        break\n",
        "    if frameId % ((int(frameRate)+1)*1) == 0:\n",
        "        face_rects, scores, idx = detector.run(frame, 0)\n",
        "        for i, d in enumerate(face_rects):\n",
        "            x1 = d.left()\n",
        "            y1 = d.top()\n",
        "            x2 = d.right()\n",
        "            y2 = d.bottom()\n",
        "            crop_img = frame[y1:y2, x1:x2]\n",
        "            data = (cv2.resize(crop_img, (128, 128))) / 255.0\n",
        "            data = data.reshape( -1,128, 128, 3)\n",
        "            prediction=model.predict(data)\n",
        "            prediction_threshold = 0.5\n",
        "            if prediction >= prediction_threshold:\n",
        "                   predicted_class = 1\n",
        "            else:\n",
        "                   predicted_class = 0\n",
        "\n",
        "            print(\"Predicted class:\", predicted_class)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
